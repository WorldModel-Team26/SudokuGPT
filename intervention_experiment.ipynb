{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "418649aa",
   "metadata": {},
   "source": [
    "# 介入実験ノートブック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b429e6d2-101b-45df-9958-85b10e8aa81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796b304f-0f64-46d4-ae69-b03553c08034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Othello / Intervention 関連の関数群\",\n",
    "from data import get_othello, plot_probs, plot_mentals\n",
    "from data.othello import permit, start_hands, OthelloBoardState, permit_reverse\n",
    "\n",
    "# mingpt のモジュール\",\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.model import GPT, GPTConfig, GPTforProbeIA\n",
    "from mingpt.utils import sample, intervene, print_board\n",
    "from mingpt.probe_model import BatteryProbeClassification, BatteryProbeClassificationTwoLayer\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', **{'size': 14.0})\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{lmodern}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be98be3c-f484-4a15-bbe9-a640ecb37bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "championship = False\n",
    "id_dim = 128\n",
    "how_many_history_step_to_use = 99\n",
    "exp = f\"state_tl{mid_dim}\"\n",
    "if championship:\n",
    "    exp += \"_championship\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71378fe3-d9c2-401a-b1a0-9445f6ffd242",
   "metadata": {},
   "source": [
    "# 介入設定\n",
    "Load a game from intervention benchmark and select an intervention configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de77e19-451a-4f3b-89fd-4efdba144882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 介入設定データのロード  \n",
    "with open(\"intervention_benchmark.pkl\", \"rb\") as input_file:\n",
    "    dataset = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e08851-7508-4a56-993a-0f67be5ecb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id = 777\n",
    "wtd = {\n",
    "    \"intervention_position\": permit_reverse(dataset[case_id][\"pos_int\"]), \n",
    "    \"intervention_from\": dataset[case_id][\"ori_color\"], \n",
    "    \"intervention_to\": 2 - dataset[case_id][\"ori_color\"], \n",
    "}\n",
    "\n",
    "print(wtd)\n",
    "\n",
    "# ケースのゲーム履歴（手順）を抽出\",\n",
    "completion = dataset[case_id][\"history\"]\n",
    "\n",
    "wtd_list = [wtd]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89df37-9dea-4261-94e4-b602ec8cfffb",
   "metadata": {},
   "source": [
    "# プローブのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e85d97-4f7a-4c90-99b2-9b04cae1154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = {}\n",
    "layer_s = 4\n",
    "layer_e = 9\n",
    "for layer in range(layer_s, layer_e):\n",
    "    p = BatteryProbeClassificationTwoLayer(torch.cuda.current_device(), probe_class=3, num_task=64, mid_dim=mid_dim)\n",
    "    load_res = p.load_state_dict(torch.load(f\"./ckpts/battery_othello/{exp}/layer{layer}/checkpoint.ckpt\"))\n",
    "    p.eval()\n",
    "    probes[layer] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96259d73-16a9-4ec2-94e2-1dbc294648b3",
   "metadata": {},
   "source": [
    "# GPTモデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d0f8a5-b06b-454e-a1b2-a97d719f3d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 36.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created has 1 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "othello = get_othello(ood_perc=0., data_root=None, wthor=False, ood_num=1)\n",
    "train_dataset = CharDataset(othello)\n",
    "\n",
    "mconf = GPTConfig(61, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "\n",
    "models = {}\n",
    "for layer in range(layer_s, layer_e):\n",
    "    model = GPTforProbeIA(mconf, probe_layer=layer)\n",
    "    # model = GPT(mconf)\n",
    "    if championship:\n",
    "        ckpt_path = f\"./ckpts/gpt_championship.ckpt\",\n",
    "    else:\n",
    "        ckpt_path = f\"./ckpts/gpt_synthetic.ckpt\",\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        models[layer] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc45bc-e369-44f4-bc5e-54bfec187825",
   "metadata": {},
   "source": [
    "# ゲーム進行をチェック  \n",
    "Check the partial game progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90954b-6e49-4b63-9dca-5851c748ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 介入前の局面を生成\n",
    "ab = OthelloBoardState()\n",
    "ab.update(completion, prt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dd21ce5-6c66-419f-a4d0-2a5c12896862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ゲーム履歴をトークン列に変換\n",
    "partial_game = torch.tensor([train_dataset.stoi[s] for s in completion], dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e84e85-9c75-402c-9026-6dee99e4db46",
   "metadata": {},
   "source": [
    "# 介入前の合法手リストの取得  \n",
    "Check pre-intervention ground-truth legal next-steps and the predicted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7b0c20c-895c-4385-bb69-0ff45e39715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b4', 'c6', 'd3', 'e7', 'f4', 'f6']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_intv_valids = [permit_reverse(_) for _ in ab.get_valid_moves()]\n",
    "pre_intv_valids\n",
    "print('Pre-intervention valid moves:', pre_intv_valids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17993c",
   "metadata": {},
   "source": [
    "# 介入実験の実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 最初の興味のある層 (layer_s) における中間表現の取得\",\n",
    "p = probes[layer_s]\n",
    "whole_mid_act = models[layer_s].forward_1st_stage(partial_game[None, :])  # [B, T, F=512]\",\n",
    "mid_act = whole_mid_act[0, -1]\n",
    "pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)  # [64, 3]\",\n",
    "plot_mentals(plt.figure(), pre_intv_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 介入前のラベルを取得して反復介入\n",
    "labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "new_mid_act = mid_act.clone()\n",
    "for wtd in wtd_list:\n",
    "    new_mid_act = intervene(p, new_mid_act, labels_pre_intv, wtd, htd={}, plot=True)\n",
    "    pre_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bf3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 介入後の中間表現を元のテンソルに戻す\n",
    "whole_mid_act[0, -1] = new_mid_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. その後の各層（layer_s～layer_e-1）の伝播と介入の波及\n",
    "for i, layer in enumerate(range(layer_s, layer_e - 1)):\n",
    "    p = probes[layer+1]\n",
    "    whole_mid_act = models[layer_s].forward_2nd_stage(whole_mid_act, layer, layer+1)[0]  # [1, T, F=512]\",\n",
    "    mid_act = whole_mid_act[0, -1]\n",
    "    pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)\n",
    "    plot_mentals(plt.figure(), pre_intv_logits)\n",
    "    labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "    new_mid_act = mid_act.clone()\n",
    "    for config in wtd_list:\n",
    "        new_mid_act = intervene(p, new_mid_act, labels_pre_intv, config, htd={}, plot=True)\n",
    "        pre_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)\n",
    "        labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "        whole_mid_act[0, -1] = new_mid_act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db4ed9",
   "metadata": {},
   "source": [
    "# 介入後の予測とヒートマップの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ad9b4d1-5fd5-48db-add4-fa03305ad661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 介入前の予測 (heatmap 用に reshape してプロット)\n",
    "pre_intv_pred, _ = model(partial_game[None, :])  # [B, T, F=512]\n",
    "# no history activations used here, that's why the prediction map is different to across layers\n",
    "pre_intv_pred = pre_intv_pred[0, -1, 1:]\n",
    "padding = torch.zeros(2).cuda()\n",
    "pre_intv_pred = torch.softmax(pre_intv_pred, dim=0)\n",
    "pre_intv_pred = torch.cat([pre_intv_pred[:27], padding, pre_intv_pred[27:33], padding, pre_intv_pred[33:]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71efd0e-2614-41d5-9ac0-7d9bdf212c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "vv = 0.2\n",
    "sns.heatmap(pre_intv_pred.detach().cpu().numpy().reshape(8, 8), vmin=0., vmax=vv, \n",
    "            yticklabels=list(\"ABCDEFGH\"), xticklabels=list(range(1,9)), square=True, \n",
    "            annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 介入後の予測   \n",
    "tb_resumed = whole_mid_act\n",
    "post_intv_pred, _ = models[layer_s].predict(tb_resumed)\n",
    "post_intv_pred = post_intv_pred[0, -1, 1:]\n",
    "post_intv_pred = torch.softmax(post_intv_pred, dim=0)\n",
    "post_intv_pred = torch.cat([post_intv_pred[:27], padding, post_intv_pred[27:33], padding, post_intv_pred[33:]], dim=0)\n",
    "fig2 = plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(post_intv_pred.detach().cpu().numpy().reshape(8, 8), annot=True, fmt='.2f')\n",
    "plt.title('Post-intervention Prediction Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da768704",
   "metadata": {},
   "source": [
    "# Attribution Plot via Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55dd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下は、介入実験済みの局面に対して，全ての合法手に関する Attribution (寄与度) ヒートマップをプロットする例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下は、介入実験済みの局面に対して，全ての合法手に関する Attribution (寄与度) ヒートマップをプロットする例\n",
    "tbu = pre_intv_valids\n",
    "total = len(tbu)\n",
    "rows = math.ceil(total / 4)\n",
    "\n",
    "fig, axs = plt.subplots(rows, 4, figsize=(30, rows * 8), dpi= 80, facecolor='w', edgecolor='k')\n",
    "axs = axs.flat\n",
    "\n",
    "# gems には介入実験の結果（例: 介入前 'pre' の予測結果など）を格納していると仮定\n",
    "gems = {}\n",
    "gems[\"pre\"] = pre_intv_pred.detach().cpu().numpy().reshape(8, 8)\n",
    "\n",
    "for i, tobe_tcaved in enumerate(tbu):\n",
    "    pred = permit(tobe_tcaved)  # 0-63\n",
    "    r_pred, c_pred = pred // 8, pred % 8\n",
    "\n",
    "    tbp = np.zeros((8, 8), )\n",
    "    pre = gems[\"pre\"]\n",
    "    for k, w in gems.items():\n",
    "        if k == \"pre\":\n",
    "            continue\n",
    "        move = permit(k)  # 0-63\n",
    "        r, c = move // 8, move % 8\n",
    "        tbp[r, c] = - w[r_pred, c_pred] + pre[r_pred, c_pred]\n",
    "    ab.plot_hm(axs[i], tbp.flatten(), permit(tobe_tcaved), logit=True)\n",
    "\n",
    "plt.suptitle('Attribution via Intervention Heatmaps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e559c0-78b1-4114-af0f-521db6b7107d",
   "metadata": {},
   "source": [
    "## Check post-intervention ground-truth next steps\n",
    "0 for white; 1 for blank; 2 for black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "554c0a8c-8746-4089-a888-bb28fa1aaf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "['e6', 'd6', 'c3', 'f3', 'c4']\n",
      "a                \n",
      "b                \n",
      "c     X X        \n",
      "d       X X O    \n",
      "e       O X O    \n",
      "f     O          \n",
      "g                \n",
      "h                \n",
      "  1 2 3 4 5 6 7 8\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['b3', 'b4', 'c6', 'd3', 'f4']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htd = {\"lr\": 1e-3, \"steps\": 1000, \"reg_strg\": 0.2}\n",
    "for wtd in wtd_list:\n",
    "    move = permit(wtd[\"intervention_position\"])\n",
    "    r, c = move // 8, move % 8\n",
    "    ab.state[r, c] = wtd[\"intervention_to\"] - 1\n",
    "ab.__print__()\n",
    "post_intv_valids = [permit_reverse(_) for _ in ab.get_valid_moves()]\n",
    "post_intv_valids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd486f-ec23-4700-bf5a-9d85eed8813d",
   "metadata": {},
   "source": [
    "## Intervene and observe how the world representation changes along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef294d-ad0b-4256-bd16-0ef533250e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(layer_e - layer_s, 2, figsize=(8 * (1), 8 * (layer_e - layer_s)), dpi= 80, facecolor='w', edgecolor='k')\n",
    "# two rows for the intervened layer layer_s, one for the rest\n",
    "if len(axs.shape) == 1:\n",
    "    axs = axs[:, None]\n",
    "\n",
    "p = probes[layer_s]\n",
    "whole_mid_act = models[layer_s].forward_1st_stage(partial_game[None, :])  # [B, T, F=512]\n",
    "\n",
    "# intervene at the earlest interested layer \n",
    "mid_act = whole_mid_act[0, -1]\n",
    "pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "plot_mentals(axs[0, 0], pre_intv_logits)\n",
    "axs[0, 0].set_title(f\"Pre-intervention Probe Result \\n at the {layer_s}-th Layer\")\n",
    "labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "new_mid_act = mid_act.clone()\n",
    "for wtd in wtd_list:\n",
    "    new_mid_act = intervene(p, new_mid_act, labels_pre_intv, wtd, htd, plot=True)\n",
    "    pre_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "post_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "plot_mentals(axs[0, 1], post_intv_logits)\n",
    "axs[0, 1].set_title(f\"Post-intervention Probe Result \\n at the {layer_s}-th Layer\")\n",
    "# swap in \n",
    "whole_mid_act[0, -1] = new_mid_act\n",
    "\n",
    "for i, layer in enumerate(range(layer_s, layer_e - 1)):  # 4, 5, 6, 7, indices of the layers to be passed\n",
    "    p = probes[layer+1]\n",
    "    whole_mid_act = models[layer_s].forward_2nd_stage(whole_mid_act, layer, layer+1)[0]  # [1, T, F=512]\n",
    "    \n",
    "    # intervene the output of the features freshly out\n",
    "    mid_act = whole_mid_act[0, -1]\n",
    "    pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    plot_mentals(axs[i+1, 0], pre_intv_logits)\n",
    "    axs[i+1, 0].set_title(f\"Post-intervention Probe Result \\n at the {layer+1}-th Layer\")\n",
    "    labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "    new_mid_act = mid_act.clone()\n",
    "    for wtd in wtd_list:\n",
    "        new_mid_act = intervene(p, new_mid_act, labels_pre_intv, wtd, htd, plot=True)\n",
    "        pre_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "        labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "    post_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    plot_mentals(axs[i+1, 1], post_intv_logits)\n",
    "    axs[i+1, 1].set_title(f\"Post-intervention Probe Result \\n at the {layer+1}-th Layer\")\n",
    "    # swap in \n",
    "    whole_mid_act[0, -1] = new_mid_act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931979c-6224-42e9-8756-3b04706a0091",
   "metadata": {},
   "source": [
    "## Compare post-intervention prediction heatmap with pre-intervention ones\n",
    "Underscored tiles are the ground-truth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "othello"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
